{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(infile, outfile, dictfile):\n",
    "    \n",
    "    raw = pd.read_csv(infile, delimiter='\\t', names=[\"1gram\", \"year\", \"occ\"], \n",
    "                      converters={\"1gram\":lambda x: str(x), \"year\":lambda x: int(x), \"occ\":lambda x: int(x)},\n",
    "                      engine='c', quoting=3, encoding='latin-1')\n",
    "    \n",
    "    # break up each word into its own sub-array\n",
    "    break_inds = np.where(raw[\"1gram\"] != np.roll(raw[\"1gram\"], 1))[0]\n",
    "    \n",
    "    years = np.array(raw[\"year\"])\n",
    "    years_each_word = np.array(np.split(years, break_inds[1:]))\n",
    "    \n",
    "    all_words = np.array(raw[\"1gram\"])[break_inds]\n",
    "    print(all_words[0])\n",
    "    print(all_words[-1])\n",
    "    \n",
    "    # only use data from words without \"wacky\" characters and that have appeared continuously\n",
    "    usable_inds = []\n",
    "    for index in range(years_each_word.size):\n",
    "        try:\n",
    "            if all_words[index] == all_words[index].encode(\"latin-1\").decode(\"utf-8\"):\n",
    "                if (years_each_word[index] - np.roll(years_each_word[index], 1) < 2).all():\n",
    "                    if years_each_word[index].min() <= 1800 and years_each_word[index].max() == 2008:\n",
    "                        usable_inds.append(index)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f'WARNING - unicode decode error, ignoring word {index}...')\n",
    "\n",
    "    years_each_word = years_each_word[usable_inds]\n",
    "    \n",
    "    if outfile:\n",
    "        # writing the counts for each word\n",
    " \n",
    "        counts = np.array(raw[\"occ\"])\n",
    "        counts_each_word = np.array(np.split(counts, break_inds[1:]))\n",
    "        counts_each_word = counts_each_word[usable_inds]\n",
    "    \n",
    "        # axes (word, year)\n",
    "        # try filling with 1 not 0...\n",
    "        full_counts_each_word = np.vstack([counts_each_word[index][:209] for index in range(len(usable_inds))])\n",
    "\n",
    "        # write counts\n",
    "        with open(outfile, 'ba') as f:\n",
    "            np.savetxt(f, full_counts_each_word, fmt='%u', delimiter=',')\n",
    "    \n",
    "    if dictfile:\n",
    "\n",
    "        usable_words = all_words[usable_inds]\n",
    "\n",
    "        # write words to ordered \"dictionary\"\n",
    "        with open(dictfile, 'a+') as f:\n",
    "            for word in usable_words:\n",
    "                f.write(word)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "ï¬ow\n",
      "0\n",
      "$\n",
      "ï¬ourished\n",
      "1\n",
      "$0.007\n",
      "ï¼\n",
      "2\n",
      "$0.00\n",
      "ï¼\n",
      "3\n",
      "$0.002\n",
      "ï¬y\n",
      "4\n",
      "$0.0\n",
      "ï¬ying\n",
      "5\n",
      "$0.0005\n",
      "ï¬ight\n",
      "6\n",
      "$0\n",
      "ï¬xing\n",
      "7\n",
      "\"\"\"ê\u0011\"\n",
      "ï¬oating\n",
      "WARNING - unicode decode error, ignoring word 0...\n",
      "8\n",
      "!\n",
      "ï¬uid\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "outfile = \"../ngram_data/full_counts_1800_contonly.csv\"\n",
    "dictfile = \"../ngram_data/py_dict_1800_contonly.txt\"\n",
    "for i in range(10):\n",
    "    name = f\"../ngram_data/googlebooks-eng-1M-1gram-20090715-occonly{i}.csv\"\n",
    "    reformat(name, outfile, dictfile)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
